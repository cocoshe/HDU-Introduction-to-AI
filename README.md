# HDU-Introduction-to-AI
æ­ç”µäººå·¥æ™ºèƒ½å¯¼è®ºè¯¾ç¨‹éªŒæ”¶ä½œä¸š

## å®Œæˆä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œçš„ä¿®æ”¹
> æºä»£ç è€å¸ˆå·²ç»™å‡º,åˆ¶ä½œä¸€äº›ä¿®æ”¹å³å¯,
> å¯¼è®ºè¯¾ç›®çš„åœ¨äºå¼•å¯¼èŒæ–°å…¥å‘ç‚¼ä¸¹å­¦

## éªŒæ”¶è¦æ±‚å¦‚ä¸‹ 
![img.png](img.png)


## Quick Start:
```python
# CNN
python CNN.py --model cnn
# Vit
python CNN.py --model vit
```

## Level1: 
+ åœ¨`Net`ç±»çš„`__init__`æ–¹æ³•ä¸­,æ·»åŠ `self.conv`,ä¿è¯ä¸Šä¸€å±‚çš„è¾“å‡ºç»´åº¦ä¸ä¸‹ä¸€å±‚çš„è¾“å…¥ç»´åº¦ä¸€è‡´å³å¯
+ åœ¨`Net`ç±»çš„`forward`æ–¹æ³•ä¸­, æŠŠ`__init__`ä¸­å®šä¹‰çš„å±‚åŠ è¿›å»å³å¯(ä¿è¯ä¸Šä¸€å±‚çš„è¾“å‡ºç»´åº¦ä¸ä¸‹ä¸€å±‚çš„è¾“å…¥ç»´åº¦ä¸€è‡´å³å¯)
> ps: `__init__`åªæ˜¯åšä¸€ä¸ªå®šä¹‰,ç›¸å½“äºå…¶ä»–è¯­è¨€é‡Œé¢çš„æˆå‘˜å˜é‡,ç„¶ååœ¨`forward`å¯ä»¥ç”¨`self.XXXX`è°ƒç”¨.
> `forward`åœ¨è¢«callçš„æ—¶å€™è°ƒç”¨,æ¯”å¦‚`output = model(x)`,å…¶ä¸­modelæ˜¯ä¸€ä¸ªNetçš„å®ä¾‹,xæ˜¯è¾“å…¥çš„æ•°æ®
```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()  # ç»§æ‰¿nn.Moduleç±»
        self.XXXXXXXX           # è‡ªç”±å‘æŒ¥
        
    def forward(self, x):
        x = self.XXXXXXXX(x)
        return x
        
```

## Level2:
+ Kaimingå¤§ç¥çš„residual connectionæ€æƒ³ç®€å•,å°±æ˜¯ç±»ä¼¼äºç”µè·¯çš„"çŸ­è·¯"
+ çŸ­è·¯çš„æ–¹å¼å¤§æŠµæœ‰ä¸¤ç§:
1. ç›´æ¥ç›¸åŠ 
```python
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x0 = x
        x = self.conv3(x)
        x = self.conv4(x)
        x = x + x0  # residual connection 1
        return x
```
2. ç»´åº¦å †å (concat)
```python
        x = torch.concat([x, x0], 1)  # residual connection 2  # ä¸¤ä¸ª[bs, 32, 7, 7]çš„tensorå †å èµ·æ¥(dim=1),ç»´åº¦ä¸º[bs, 64, 7, 7]
        x = self.conv(x)  # [bs, 64, 7, 7] -> [bs, 32, 7, 7]  # è¿™é‡Œè¦å˜å›å»
        x = x.view(x.size(0), -1)  # å±•å¹³å¤šç»´çš„å·ç§¯å›¾æˆ (batch_size, 32 * 7 * 7)
        output = self.out(x)
        return output
```


## Level3:
+ Vit(Vision Transformer)
+ æŠŠåŸæœ¬ç”¨åœ¨NLPçš„Transformerç”¨åˆ°äº†CVä¸Š, å¼•å…¥Attentionæœºåˆ¶

**å¤§æ¦‚æµç¨‹:**
1. `patch_embedding`: input: `[bs, in_channels, h, w]` -> output: `[bs, embed_dim, num_patches_in_h, num_patches_in_w]` å…¶å®å°±æ˜¯åšäº†ä¸€ä¸ª `kernel` å’Œ `strip` ä¸º `patch_size` çš„ `conv`
2. `flatten`: input: `[bs, embed_dim, num_patches_in_h, num_patches_in_w]` -> output: `[bs, embed_dim, num_patches_in_h * num_patches_in_w]`
3. `transpose`: input: `[bs, embed_dim, num_patches_in_h * num_patches_in_w]` -> output: `[bs, num_patches_in_h * num_patches_in_w, embed_dim]`
   (æ˜¯ä¸æ˜¯éå¸¸åƒNLPé‡Œé¢çš„`[bs, seq_len, embed_dim]`äº†å‘¢?æç„¶å¤§æ‚Ÿ.jpg)
4. add `cls_tokens`(åšä¸€ä¸ªdim=1çš„concat): input: `[bs, num_patches_in_h * num_patches_in_w, embed_dim]` -> output: `[bs, num_patches_in_h * num_patches_in_w + 1, embed_dim]`
   (ç›¸å½“äºç»™æ¯å¥è¯åŠ ä¸Šäº†ä¸€ä¸ª`<cls>`, ç›®çš„æ˜¯ä½œä¸ºä¸€ä¸ª**æ›´åŠ å…¬å¹³çš„åˆ†ç±»token**)
5. `position_embedding`: ç»´åº¦ä¸å˜, åªæ˜¯ç»™ä¸€ä¸ªç›¸åŒçš„tensorå’Œå‰é¢ç›¸åŠ ,è¿™é‡ŒåŒºåˆ«äº `position_encoding`(å®ƒæ˜¯ä¸å¯å­¦ä¹ çš„,å…·ä½“å¯è§ã€ŠAttention is all you needã€‹)

è¿™æ—¶å€™å·²ç»å˜æˆNLPé‡Œé¢çš„å½¢å¼äº†,åé¢å°±æ­£å¸¸å½“NLPå¤„ç†å³å¯
6. `Encoder`: é‡Œé¢æœ‰`depth`å±‚`EncoderLayer`
7. `EncoderLayer`: é‡Œé¢æ˜¯`MultiheadAttention`å’Œ`FeedForward`
8. `MultiheadAttention`: é‡Œé¢æœ‰`num_heads`ä¸ª`Attention`
9. `Attention`: é‡Œé¢æœ‰`Q`, `K`, `V`, æŒ‰ç…§å…¬å¼æ¥å°±è¡Œäº†, `QK'`ä¹˜ä¸€ä¹˜, æ¥softmax, é™¤ä»¥`sqrt(dim)`, ä¹˜ä¸€ä¹˜`V`,æœ€åç»´åº¦å˜å›æ¥äº†,æ‰€ä»¥éšä¾¿å 
10. å…³äº`norm`é€‰æ‹©: éƒ½æ˜¯ç”¨`nn.LayerNorm`, å› ä¸ºå¯¹ä¸€å¥è¯è€Œè¨€, å®ƒçš„ç‰¹å¾æ˜¯"ä¸€å¥è¯ç›¸å…³çš„", å’Œbatchä¸­å…¶ä»–æ ·æœ¬çš„ç‰¹å¾åŸºæœ¬ä¸Šæ²¡å…³ç³»,å› ä¸ºä»–ä»¬æ˜¯ä¸ç›¸å…³çš„ä¸¤å¥è¯

> è¯•äº†ä¸€ä¸‹, Vitåœ¨MNISTä¸Šæ•ˆæœè¿˜ä¸å¦‚CNN ğŸ¤¡, æ”¶æ•›å¤ªæ…¢äº†, å¯èƒ½æ˜¯position_embeddingçš„ä½ç½®ä¿¡æ¯å¤ªå¼±äº†, è€Œä¸”éœ€è¦å­¦ä¹ , 
> ä½†CNNä¸ç”Ÿä¿±æ¥çš„ä½ç½®ä¿¡æ¯æå–çš„ä¼˜è¶Šæ€§è¶³å¤Ÿè§£å†³è¿™ä¸ªç®€å•é—®é¢˜, Vitåœ¨è¿™é‡Œæ›´åƒæ˜¯å¤§ç‚®æ‰“èšŠå­äº†